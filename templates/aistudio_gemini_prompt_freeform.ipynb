{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a2d326-8b00-4215-ee9b-13d590f2f735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"ğŸ”‘\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = 'gemini-1.5-pro' # @param {isTemplate: true}\n",
        "contents_b64 = 'W10=' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"ğŸ“ Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocd6brCaYgCM",
        "outputId": "8208bff6-ae49-496f-b48e-5ecfc56421e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the video and print a confirmation.\n",
        "video_file_name = \"/content/drive/MyDrive/ç»æµå­¦/MITå¾®è§‚_x264.mp4\"\n",
        "\n",
        "print(f\"Uploading file...\")\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "print(f\"Completed upload: {video_file.uri}\")\n",
        "import time\n",
        "\n",
        "# Check whether the file is ready to be used.\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print('.', end='')\n",
        "    time.sleep(10)\n",
        "    video_file = genai.get_file(video_file.name)\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "  raise ValueError(video_file.state.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEHJ-l8Yk-3",
        "outputId": "9e7e939e-fedb-4d0d-f664-417f59e04bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/8f6j3xwzea12\n",
            "..........."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "# Create the prompt.\n",
        "prompt = \"\"\"è§’è‰²è®¾å®š: ä½ æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œæ­£åœ¨å­¦ä¹ åˆ‘æ³•è¯¾ï¼Œæƒ³è¦åšåˆ°èƒ½å¤Ÿæ¸…æ™°ã€å‡†ç¡®åœ°ç†è§£æ³•å¾‹æ–‡æœ¬ï¼Œå¹¶èƒ½ç»“åˆå®é™…æ¡ˆä¾‹è¿›è¡Œåˆ†æã€‚\n",
        "ä»»åŠ¡æè¿°: è¯·è§‚çœ‹æˆ‘ä¸‹é¢ç»™å‡ºçš„åˆ‘æ³•æ€»è®ºçš„å…³äºè´¿èµ‚çŠ¯ç½ªçš„è¯¾ç¨‹è§†é¢‘ã€‚åœ¨è§‚çœ‹å®Œè§†é¢‘åï¼Œè¯·å›ç­”ä¸‹åˆ—é—®é¢˜ã€‚ç¡®ä¿ä½ çš„å›ç­”è¯¦ç»†ã€å‡†ç¡®ï¼Œå¹¶ç»“åˆè§†é¢‘ä¸­çš„ç›¸å…³ä¿¡æ¯æ¥æ”¯æŒä½ çš„ç­”æ¡ˆã€‚\n",
        "\"\"\"\n",
        "contents = [prompt]\n",
        "\n",
        "print(\"Making LLM inference request...\")\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream,\n",
        ")\n",
        "print(\"Successfully generating reponse:\")\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "6TD1HaXTLkAw",
        "outputId": "349fcdae-a0d1-409d-fbc6-a518db41d151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n",
            "Successfully generating reponse:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "è¯·æ‚¨æä¾›åˆ‘æ³•æ€»è®ºå…³äºè´¿èµ‚çŠ¯ç½ªçš„è¯¾ç¨‹è§†é¢‘ã€‚æˆ‘çœ‹å®Œåä¼šå°½åŠ›æŒ‰ç…§æ‚¨çš„è¦æ±‚ï¼Œä»¥å­¦ç”Ÿçš„èº«ä»½è¯¦ç»†ã€å‡†ç¡®åœ°å›ç­”æ‚¨çš„é—®é¢˜ï¼Œå¹¶ç»“åˆè§†é¢‘å†…å®¹è¿›è¡Œåˆ†æã€‚\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9194d0a2-8ff0-4913-905b-49b0ae16d578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n",
            "Successfully generating reponse:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure! Here are the answers to your questions based on the provided video clip.\n\n**CONCEPT PROBLEMS:**\n1. The primary objective of firms is to maximize their profits, which is defined as revenue minus costs.\n\n\n2. The difference between the short-run and the long-run from the perspective of production theory is that in the short-run, some inputs are fixed, while in the long-run, all inputs are variable.\n\n\n3. All of the listed options are properties of isoquants.\n\n\n4. A production function in which doubling all inputs causes output to more than double is known asÂ increasing returns to scale.\n\n\n5. In the short run, the marginal cost is defined as the wage rate multiplied by the number of hours needed to produce one additional unit.\n\n\n6. An isocost line is defined as combinations of labor and capital that yield the same levels of cost.\n\n\n7. The economically efficient point of production for firms is identified by the tangency of an isoquant with an isocost line.\n\n\n8. The example of McDonaldâ€™s demonstrates the concept ofÂ labor becoming less productive, not capital. This occurs in a short-run analysis. In a long-run analysis, both capital and labor are variable, as both can be changed. With the two isoquants given, if capital becomes less productive as the business expands, the slope of the long-run expansion path will decrease as output increases, or as L increases. This means the firm will become more capital-intensive with more expansion. The long-run expansion path would be concave.\n\n\n9. The cost of a law school education would be considered sunk costs. This is because these are expenses that can not be recovered once you have graduated law school.\n\n\n10. Short-run choices are 1, and 3. Long-run choices are 2, 4 and 5.\n\n\n11. In the long-run, all inputs are variable. Since fixed costs are defined as costs that do not vary with the level of output, there can be no fixed costs in the long run. \n\n\n12. The manager should assess whether each worker is worth less than the previous workers by using the marginal product of labor.Â After calculating the value of each worker and calculating the cost of an additional worker, the manager can then evaluate the options ofÂ increasing the number of workers or adding machines.\n\n\n13. Adding a 19-year-old student to the class will decrease the average age from 23.7 years. This is an example of diminishing marginal product. The average value decreases as each marginal value is added.\n\n\n14. Barry Bondâ€™s career home run average increased after the 2001 season. His performance increased his home run average. This is because the marginal value (73 home runs) was higher than the average value (33 home runs). The average increases with each marginal value if the marginal value is higher than the average value.\n\n\n15. If the firm is at the minimum point of its average cost curve, that means the marginal cost is equal to the average cost. The firm would not alter the size of its plant unless the prices of the inputs changed.\n\n\n16. The difference between average total cost and average variable cost decreases with each unit of production, because the average fixed costs decrease with each unit of production, and therefore decreases the difference between average total cost and average variable cost.\n\n\n17. This information is not covered in the lecture clip.\n\n\n18. Out of the listed firms, you would expect diseconomies of scale to set in at relatively low levels of output for the restaurant, copy shop and newspaper.Â This is due to higher fixed costs, which need to be spread out amongst many units of production, and also due to the diminishing marginal returns of labor that result from a lack of machines to aid in production.\n\n\n19. As car repair shops require more computerized testing equipment to repair newer cars, the long-run average total cost curves will likely rise, as the increased use of technology increases costs.\n\n\n**NUMERICAL PROBLEMS:**\n1. \n1. The marginal product of the second janitor is 4 classrooms.\n2. The average product of four janitors is 4 classrooms.\n3. The addition of the third janitor is associated withÂ decreasing marginal returns because the marginal product of labor is less than the previous marginal product.Â \n4. The addition of the fourth janitor is associated with decreasing marginal returns because the marginal product of labor is less than the previous marginal product.\n5. The addition of the seventh janitor is associated with negative marginal returns because the total product decreases as a result.\n6. The image canâ€™t be provided since the video did not show the drawing process.\n7. The slope of the total product curve is the marginal product of labor. Therefore, the slope values are 3, 4, 5, 4, 1, 0, and -1.\n8.\n1. The marginal product of labor increases when the slope of the total product curve is positive and increasing.\n2. The marginal product of labor decreases when the slope of the total product curve is positive and decreasing.\n3. The marginal product of labor is negative when the slope of the total product curve is negative.\n\n\n2. The total cost isÂ $150,000.\n\n\n3. The error in the directorâ€™s recommendation is that she included overhead costs. Overhead costs are a type of sunk costs, which should not be included when making decisions about production.\n\n\n4. \n1. The average fixed cost of cleaning three classrooms is $33.33.\n2. The average variable cost of cleaning three classrooms is $33.33.\n3. The average fixed cost of cleaning seven classrooms is $14.29.\n4. The average variable cost of cleaning seven classrooms is $28.57.\n5. The marginal cost of cleaning the seventeenth classroom is $100.\n6. The average total cost of cleaning twelve classrooms is $33.33.\n\n\n5. The information provided is insufficient to sketch the curves. The variable costs of publishing magazines are labor, paper and ink, electricity and marketing. Fixed costs are printing presses and building rent.\n\n\n6. The calculations are complex and canâ€™t be provided without more detailed information.\n\n\n7. \n1. The image canâ€™t be provided, since the video did not show the drawing process.\n2. The image canâ€™t be provided.\n3. The cost per knife is decreasing in the region of the long-run average cost curve that corresponds to economies of scale.\n4. The cost per knife is constant in the region of the long-run average cost curve that corresponds to constant returns to scale.\n5. The cost per knife is increasing in the region of the long-run average cost curve that corresponds to diseconomies of scale.\n\n\n8. If the marginal product of capital is 60 and the price of capital is $6, and the marginal product of labor is 20 and the price of labor is $2.50, the firm should increase the amount of labor and decrease the amount of capital used. This is because the bang-for-the-buck of labor is 8, while the bang-for-the-buck of capital is 10. Therefore, the firm can achieve a greater marginal product per dollar using capital.\n\n\n9. The price of labor must be $5 per unit.\n\n\n10.\n1. The marginal product of capital must be 100.\n2. The firm would become more labor-intensive since capital becomes more expensive to use relative to labor. \n\n\nI hope this is helpful. Let me know if you have any other questions."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "# Create the prompt.\n",
        "prompt = \"\"\"\n",
        "Role: You are a very useful video assistant who can watch video content and answer questions related to it.\n",
        "Task: Please watch the following news report video and answer the questions listed below based solely on the content of the video. Provide clear and accurate answers. The format should list the question first, followed by the answer.\n",
        "Question listï¼š\n",
        "1.\tHow many active fires are currently burning in Los Angeles?\n",
        "2.\tWhat are the two main environmental factors that created conditions for the fires to spread?\n",
        "3.\tWhat type of winds are particularly concerning in the area?\n",
        "4.\tWhat measures have been taken to protect abandoned properties?\n",
        "5.\tHow have local communities responded to the emergency services being stretched thin?\n",
        "6.\tWhat resources are the local volunteers using to help fight the fires?\n",
        "7.\tWhy did local volunteers feel their involvement was particularly valuable?\n",
        "8.\tWhat is the geographical location of Altadena relative to the danger?\n",
        "9.\tWhat historical climate milestone was reached last year according to the report?\n",
        "10.\tWhat warning is given about potential deaths?\n",
        "11.\tWhat is the mood among residents about rebuilding?\n",
        "12.\tWhat is the current state of the emergency services according to the report?\n",
        "13.\tHow do we know that both wealthy and less affluent areas are affected by the fires, and what specific areas illustrate this contrast?\n",
        "14.\tWhat evidence does the report provide about both immediate and long-term climate concerns?\n",
        "15.\tWhat was Stephanie's attitude toward the future despite losing her home?\n",
        "16.\tWho is Tavia Weinman and what was notable about her situation? What specific item was she looking for in the ruins?\n",
        "17.\tWhat are the five fires currently burning, and which one is located the furthest south and what is its containment level?\n",
        "18.\tWhat firefighting methods can you see being implemented from the video?\n",
        "19.\tHow is the reporter Emma Vardy dressed in the video?\n",
        "20.\tWhat were the scenes on Fair Oaks Avenue like before and after the fire, please describe according to the video footage.\n",
        "21.\tHow does the video vividly illustrate the changes in average daily temperatures since 1940, and what is the trend of these changes?\n",
        "22.\tWho in the report says, \"It's the warmest period in at least 100,000 years.\"\n",
        "\n",
        "\"\"\"\n",
        "contents = [video_file, prompt]\n",
        "\n",
        "print(\"Making LLM inference request...\")\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream,\n",
        ")\n",
        "print(\"Successfully generating reponse:\")\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yoL3p3KPylFW"
      },
      "outputs": [],
      "source": [
        "# @title Show the conversation, in colab.\n",
        "import mimetypes\n",
        "\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"ğŸ“ Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "\n",
        "\n",
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}